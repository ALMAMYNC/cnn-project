{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70eaaa51-5c99-491a-932e-d5b914dc2c4e",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#478CCF; color:white; text-align:center; padding:10px;\"> EXPOSE SUR L'ARCHITECTURE ALEXNET\n",
    " </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e74a45-3e40-419a-8e86-9b1d91dcbc28",
   "metadata": {},
   "source": [
    "<img src=\"images/AlexNet0.webp\" alt=\"Architecture AlexNet\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd5396-4e92-4f0b-9c4a-4d456555284a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;font-size:40px;font-family:Georgia;text-align:center;\"><strong>SOMMAIRE <strong style=\"color:#ff0000;font-size:37px;font-family:Georgia;\"></h1>\n",
    "\n",
    "1. [Definition d'AlexNet.](#1)\n",
    "2. [Provenance d'AlexNet.](#2)\n",
    "3. [Probleme a regler.](#3)\n",
    "4. [Quelques vocabulaires.](#4)\n",
    "5. [Architecture d'AlexNet.](#5)\n",
    "6. [Implementation du code d'AlexNet.](#6)\n",
    "7. [Conclusion.](#7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea0915-f5cb-4303-926c-26f85953d312",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<p style=\"background-color:#478CCF;font-family:Georgia;color:teal;font-size:105%;text-align:center;border-radius:10px 10px;border-style: solid;border-width:17px;border-color:#478CCF;\"></p>\n",
    "<h1 style=\"color:black;font-size:32px;font-family:Georgia;text-align:center;\"><strong>Definition <strong style=\"color:#ff0000;font-size:30px;font-family:Georgia;\"><strong style=\"color:black;font-size:32px;font-family:Georgia;\">D'AlexNet</strong></strong></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1ab24-dc00-4a74-a6d3-52d247f4b803",
   "metadata": {},
   "source": [
    "<p style =\"color:black; font-size:20px\"> <strong>AlexNet</strong> est une architecture de réseau de neurones convolutifs (CNN) conçue pour la reconnaissance d'images à grande échelle. Elle se distingue par ses couches convolutives profondes et ses techniques avancées de régularisation, ce qui lui permet d'exceller dans la classification d'images complexes. AlexNet a introduit plusieurs innovations importantes dans le domaine des réseaux de neurones, notamment l'utilisation de la fonction d'activation ReLU (Rectified Linear Units), la normalisation locale et le dropout.<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ee1f0-5448-4c8d-b051-d26bfe78e9aa",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<p style=\"background-color:#478CCF;font-family:Georgia;color:teal;font-size:105%;text-align:center;border-radius:10px 10px;border-style: solid;border-width:17px;border-color:#478CCF;\"></p>\n",
    "<h1 style=\"color:black;font-size:32px;font-family:Georgia;text-align:center;\"><strong>Provenance <strong style=\"color:#ff0000;font-size:30px;font-family:Georgia;\"><strong style=\"color:black;font-size:32px;font-family:Georgia;\"> d'AlexNet</strong></strong></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff50847d-d632-420c-906e-7253c0442cc4",
   "metadata": {},
   "source": [
    "<h3>Origine et Contexte :</h3>\n",
    "<p style =\"color:black; font-size:20px\">\n",
    "AlexNet a été développé par Alex Krizhevsky, Ilya Sutskever et Geoffrey Hinton. Il a été présenté pour la première fois en 2012 lors de la conférence sur les systèmes de traitement de l'information neuronale (Neural Information Processing Systems - NeurIPS). L'architecture a été conçue dans le contexte de la "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffbe61-494b-47a3-8ed8-3276f5e5d93d",
   "metadata": {},
   "source": [
    "<img src=\"images/alexnetScore.webp\" alt=\"Architecture AlexNet\" height=\"20%\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ae3fa-7c50-4a41-b4e0-4c0b87fda2bd",
   "metadata": {},
   "source": [
    "compétition ImageNet Large Scale Visual Recognition Challenge (ILSVRC) de 2012.\n",
    "</p>\n",
    "\n",
    "<h3>Compétition ImageNet :</h3>\n",
    "<p style =\"color:black; font-size:20px\">\n",
    "ImageNet est une base de données d'images massives qui contient des millions d'images annotées manuellement réparties en plusieurs milliers de catégories. Le défi ILSVRC consiste à classer ces images dans les bonnes catégories. AlexNet a participé à ce défi et a obtenu des résultats remarquables, réduisant l'erreur top-5 de manière significative par rapport aux méthodes précédentes.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba397e-4e13-4527-8b82-14c089ce7931",
   "metadata": {},
   "source": [
    "<img src=\"images/imagenet.webp\" alt=\"Architecture AlexNet\" height=\"20%\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfee953-8573-4234-8775-9e8eff8db5a1",
   "metadata": {},
   "source": [
    "<h3>Impact et Influence :</h3>\n",
    "<p style =\"color:black; font-size:20px\">\n",
    "La victoire d'AlexNet au ILSVRC 2012 a marqué un tournant dans le domaine de la vision par ordinateur et de l'apprentissage profond. Elle a démontré la puissance des réseaux de neurones convolutifs profonds et a ouvert la voie à une série de recherches et de développements dans ce domaine. AlexNet a inspiré de nombreuses architectures ultérieures, telles que VGG, GoogLeNet et ResNet, qui ont continué à améliorer les performances des systèmes de reconnaissance d'images.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea18d72-ccd9-4d09-8a4f-7dfb2694ea05",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<p style=\"background-color:#478CCF;font-family:Georgia;color:teal;font-size:105%;text-align:center;border-radius:10px 10px;border-style: solid;border-width:17px;border-color:#478CCF;\"></p>\n",
    "<h1 style=\"color:black;font-size:32px;font-family:Georgia;text-align:center;\"><strong>Probleme <strong style=\"color:#ff0000;font-size:30px;font-family:Georgia;\"><strong style=\"color:black;font-size:32px;font-family:Georgia;\"> a regler</strong></strong></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5a25e-23c7-42ec-bb71-1b240b159150",
   "metadata": {},
   "source": [
    "<ol style=\"color:black; font-size:20px\">\n",
    "<li>Capacité de Modélisation Insuffisante des Réseaux Anciens\n",
    "Problème : Les architectures de CNN antérieures étaient relativement peu profondes et avaient une capacité limitée à modéliser des relations complexes dans les données d'images.\n",
    "Solution : AlexNet, avec ses 8 couches (5 convolutives et 3 fully connected), a significativement augmenté la profondeur du réseau, permettant une extraction de caractéristiques plus riche et plus détaillée</li>\n",
    "\n",
    "<li>Surapprentissage (Overfitting)\n",
    "Problème : Les modèles de réseaux de neurones peuvent facilement surapprendre les données d'entraînement, surtout lorsqu'ils sont profonds et ont de nombreux paramètres.\n",
    "Solution : AlexNet a introduit l'utilisation du dropout dans les couches fully connected pour réduire le surapprentissage. Le dropout consiste à ignorer aléatoirement certains neurones pendant l'entraînement, ce qui aide à généraliser le modèle.</li>\n",
    "\n",
    "<li>Normalisation des Caractéristiques\n",
    "Problème : La distribution des activations des neurones peut changer au cours de l'entraînement, ce qui peut ralentir l'apprentissage.\n",
    "Solution : AlexNet a introduit la normalisation locale (local response normalization), qui aide à stabiliser les activations et améliore la précision du modèle.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0f4b8-337b-4009-a498-aa355652ba22",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<p style=\"background-color:#478CCF;font-family:Georgia;color:teal;font-size:105%;text-align:center;border-radius:10px 10px;border-style: solid;border-width:17px;border-color:#478CCF;\"></p>\n",
    "<h1 style=\"color:black;font-size:32px;font-family:Georgia;text-align:center;\"><strong>Quelques <strong style=\"color:#ff0000;font-size:30px;font-family:Georgia;\"><strong style=\"color:black;font-size:32px;font-family:Georgia;\"> Vocabulaires</strong></strong></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04b510-c032-4da8-a1e2-0f7f8851acea",
   "metadata": {},
   "source": [
    "<ol style=\"color:black; font-size:20px\">\n",
    "    <li><strong>Convolution</strong> : Opération qui consiste à appliquer un filtre (ou noyau) sur une image pour extraire des caractéristiques comme les bords, les textures, etc.</li>\n",
    "    <li><strong>Filtre (ou Noyau)</strong> : Matrice de petite taille utilisée lors de la convolution pour détecter des caractéristiques spécifiques dans l'image d'entrée.</li>\n",
    "    <li><strong>Carte de Caractéristiques (Feature Map)</strong> : Résultat obtenu après avoir appliqué un filtre sur l'image d'entrée. Elle représente les caractéristiques extraites par le filtre.</li>\n",
    "    <li><strong>Padding</strong> : Technique utilisée pour ajouter des pixels autour des bords de l'image d'entrée, permettant de contrôler la taille de la carte de caractéristiques après la convolution.</li>\n",
    "    <li><strong>Stride</strong> : Nombre de pixels par lequel le filtre est déplacé à chaque étape de la convolution. Un stride plus grand réduit la taille de la carte de caractéristiques.</li>\n",
    "    <li><strong>Pooling</strong> : Opération de sous-échantillonnage qui réduit la dimensionnalité de la carte de caractéristiques tout en conservant les informations importantes. Les types courants sont le max pooling et le average pooling.</li>\n",
    "    <li><strong>Max Pooling</strong> : Type de pooling où la valeur maximale dans une région de la carte de caractéristiques est retenue.</li>\n",
    "    <li><strong>Average Pooling</strong> : Type de pooling où la valeur moyenne dans une région de la carte de caractéristiques est retenue.</li>\n",
    "    <li><strong>ReLU (Rectified Linear Unit)</strong> : Fonction d'activation qui introduit la non-linéarité dans le réseau. Elle remplace toutes les valeurs négatives par zéro.</li>\n",
    "    <li><strong>Dropout</strong> : Technique de régularisation qui consiste à désactiver aléatoirement un certain pourcentage de neurones pendant l'entraînement pour prévenir le surapprentissage.</li>\n",
    "    <li><strong>Batch Normalization</strong> : Technique de normalisation appliquée aux couches intermédiaires d'un réseau pour accélérer l'entraînement et améliorer la performance.</li>\n",
    "    <li><strong>Fully Connected Layer (Couche Complètement Connectée)</strong> : Couche où chaque neurone est connecté à tous les neurones de la couche précédente. Elle est généralement utilisée en fin de réseau pour la classification.</li>\n",
    "    <li><strong>Backpropagation</strong> : Algorithme d'optimisation utilisé pour ajuster les poids des filtres en fonction de l'erreur calculée lors de la phase de propagation arrière.</li>\n",
    "    <li><strong>Epoch</strong> : Un passage complet à travers l'ensemble de données d'entraînement.</li>\n",
    "    <li><strong>Learning Rate</strong> : Paramètre qui détermine la taille des mises à jour des poids lors de l'optimisation.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7ae41-95e8-4169-be9d-e4e42357ddc9",
   "metadata": {},
   "source": [
    "<a id=\"#5\"></a>\n",
    "<p style=\"background-color:#478CCF;font-family:Georgia;color:teal;font-size:105%;text-align:center;border-radius:10px 10px;border-style: solid;border-width:17px;border-color:#478CCF;\"></p>\n",
    "<h1 style=\"color:black;font-size:32px;font-family:Georgia;text-align:center;\"><strong>Architecture <strong style=\"color:#ff0000;font-size:30px;font-family:Georgia;\"><strong style=\"color:black;font-size:32px;font-family:Georgia;\"> d'AlexNet</strong></strong></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b6b40-3553-4405-bb15-7f554e8dd161",
   "metadata": {},
   "source": [
    "<img src=\"images/AlexNet1.jpg\" alt=\"Architecture AlexNet\" height=\"20%\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a43428-855e-4163-9375-ba3d25fa509a",
   "metadata": {},
   "source": [
    "<h2>.L'architecture de AlexNet, avec ses 8 couches (5 convolutives et 3 fully connected) :</h2>\n",
    "\n",
    "1. **Entrée (Input Layer) :**\n",
    "   - Image de 224x224 pixels en couleur (RGB).\n",
    "\n",
    "2. **C1 - Convolution + ReLU:**\n",
    "   - Convolution avec 96 filtres de taille 11x11 et un stride de 4.\n",
    "\n",
    "   - Sortie : 96 cartes de caractéristiques de 55x55\n",
    "   - Suivi par une normalisation locale (Local Response Normalization, LRN) et un max-pooling    avec un filtre 3x3 et un stride de 2\n",
    "\n",
    "3. **C2 - Convolution + ReLU:**\n",
    "   - Convolution avec 256 filtres de taille 5x5 et un stride de 1.\n",
    "   - Sortie : 256 cartes de caractéristiques de 27x27.\n",
    "   - Suivi par LRN et max-pooling avec un filtre 3x3 et un stride de 2.\n",
    "\n",
    "4. **C3 - Convolution + ReLU:**\n",
    "   - Convolution avec 384 filtres de taille 3x3 et un stride de 1.\n",
    "   - Sortie : 384 cartes de caractéristiques de 13x13.\n",
    "\n",
    "5. **C4 - Convolution + ReLU:**\n",
    "   - Convolution avec 384 filtres de taille 3x3 et un stride de 1\n",
    "   - Sortie : 384 cartes de caractéristiques de 13x13.\n",
    "\n",
    "6. **C5 - Convolution + ReLU:**\n",
    "   - Convolution avec 256 filtres de taille 3x3 et un stride de 1\n",
    "   - Sortie : 256 cartes de caractéristiques de 13x13.\n",
    "   - Suivi par un max-pooling avec un filtre 3x3 et un stride de 2.\n",
    "\n",
    "7. **F1 - Couche Entièrement Connectée + reLu:**\n",
    "   - 4096 neurones.\n",
    "\n",
    "8. **Output - Couche de Sortie :**\n",
    "   - 1000 neurones (correspondant aux 1000 classes d'ImageNet).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5a4e7-c673-4f2e-8b3d-b4726e4adaf6",
   "metadata": {},
   "source": [
    "<img src=\"images/AlexNet2.jpg\" alt=\"Architecture AlexNet\" height=\"20%\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff2500-23eb-4f4c-8616-a91d9dae1090",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<p style=\"background-color:#478CCF;font-family:Georgia;color:teal;font-size:105%;text-align:center;border-radius:10px 10px;border-style: solid;border-width:17px;border-color:#478CCF;\"></p>\n",
    "<h1 style=\"color:black;font-size:32px;font-family:Georgia;text-align:center;\"><strong>Implementation <strong style=\"color:#ff0000;font-size:30px;font-family:Georgia;\"><strong style=\"color:black;font-size:32px;font-family:Georgia;\"> D'AlexNet</strong></strong></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18402561-fa0c-4b37-bed1-cc437049d0d2",
   "metadata": {},
   "source": [
    "## Chargement des donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d70ff5-7eff-49bb-9d2f-67abee606e11",
   "metadata": {},
   "source": [
    "# AlexNet à partir de zéro\n",
    "\n",
    "AlexNet est un réseau neuronal convolutif profond, qui a été initialement développé par Alex Krizhevsky et ses collègues en 2012. Il a été conçu pour classer les images pour le concours ImageNet LSVRC-2010 où il a obtenu des résultats de pointe.\n",
    "Ici, je vais résumer les principaux points à retenir sur le réseau AlexNet. Tout d’abord, il fonctionnait avec des images à 3 canaux de taille (224x224x3). Il utilisait le regroupement maximal ainsi que les activations ReLU lors du sous-échantillonnage. Les noyaux utilisés pour les convolutions étaient soit 11x11, 5x5 ou 3x3 tandis que les noyaux utilisés pour le regroupement maximal avaient une taille de 3x3. Il a classé les images en 1000 classes. Il utilisait également plusieurs GPU.\n",
    "## Chargement des données\n",
    "### Jeu de données\n",
    "Commençons par charger puis prétraiter les données. Pour nos besoins, nous utiliserons le CIFAR10 ensemble de données. L’ensemble de données se compose de 60000 images couleur 32x32 dans 10 classes, avec 6000 images par classe. Il y a 50000 images d’entraînement et 10000 images de test.\n",
    "\n",
    "Voici les classes de l’ensemble de données, ainsi que 10 exemples d’images aléatoires de chacune :\n",
    "\n",
    "<img src=\"images/classes.png\" alt=\"classes\" width=\"500px\">\n",
    "\n",
    "Les classes s’excluent mutuellement. Il n’y a pas de chevauchement entre les automobiles et les camions. « Automobile » comprend les berlines, les SUV et les choses de ce genre. Le terme « camion » ne comprend que les gros camions. Ni l’un ni l’autre n’inclut les camionnettes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308c825-770a-4c4f-9f08-b120beb59fe6",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques\n",
    "Commençons par importer les bibliothèques requises et définir une variable `device`, afin que le notebook sache utiliser un GPU pour entraîner le modèle s’il est disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a29c5-1618-4d93-b80c-91c328960366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "# Configuration de l'appareil\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c0d4e-cfe4-45e0-a750-0f38ee832d6b",
   "metadata": {},
   "source": [
    "## **Chargement du jeu de données**\n",
    "En utilisant `torchvision` (une bibliothèque d’assistance pour les tâches de vision par ordinateur), nous chargerons notre ensemble de données. Cette méthode a des fonctions d’assistance qui rendent le prétraitement assez facile et direct. Définissons les fonctions `get_train_valid_loader` et `get_test_loader`, puis appelons-les pour charger et traiter notre donnée CIFAR-10 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2e00f-1e5a-4104-8994-46481c5f32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_loader(data_dir,\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.Resize((227,227)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((227,227)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=valid_transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    " \n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir,\n",
    "                    batch_size,\n",
    "                    shuffle=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # define transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=False,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "# CIFAR10 dataset \n",
    "train_loader, valid_loader = get_train_valid_loader(data_dir = './data', batch_size = 64, augment = False, random_seed = 1)\n",
    "\n",
    "test_loader = get_test_loader(data_dir = './data',\n",
    "                              batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66cdec-be78-4d43-b7cc-5aff1c58bba0",
   "metadata": {},
   "source": [
    "Décomposons le code en morceau :\n",
    "- Nous définissons deux fonctions `get_train_valid_loader` et `get_test_loader` pour charger respectivement les ensembles de formation/validation et de test.\n",
    "- Nous commençons par définir la variable `normalize` avec la moyenne et les écarts-types de chacun des canaux (rouge, vert et bleu) dans l’ensemble de données. Ceux-ci peuvent être calculés manuellement, mais sont également disponibles en ligne puisque CIFAR-10 est très populaire.\n",
    "- Pour notre jeu de données d’entraînement, nous ajoutons l’option d’augmenter également le jeu de données pour un entraînement plus robuste et augmenter le nombre d’images. Remarque : l’augmentation n’est appliquée qu’au sous-ensemble d’apprentissage et non aux sous-ensembles de validation et de test, car ils ne sont utilisés qu’à des fins d’évaluation.\n",
    "- Nous divisons le jeu de données d’entraînement en ensembles d’entraînement et de validation (ratio 90:10) et le sous-ensemble aléatoirement à partir de l’ensemble d’entraînement.\n",
    "- Nous spécifions la taille du lot et mélangeons le jeu de données lors du chargement, de sorte que chaque lot présente une certaine variation dans les types d’étiquettes qu’il possède. Cela augmentera l’efficacité de notre modèle éventuel.\n",
    "- Enfin, nous utilisons des chargeurs de données. Cela peut ne pas affecter les performances dans le cas d’un petit jeu de données comme CIFAR10, mais cela peut vraiment entraver les performances dans le cas de grands jeux de données et est généralement considéré comme une bonne pratique. Les chargeurs de données nous permettent d’itérer sur les données par lots, et les données sont chargées pendant l’itération et non toutes en même temps dans votre RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c4ebf-aa41-423e-a839-bf68a81b699e",
   "metadata": {},
   "source": [
    "## AlexNet à partir de zéro\n",
    "Commençons par le code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3430c-ec40-4596-a229-d2806c01195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee4be2-1101-4a6c-914d-49626c0e3e31",
   "metadata": {},
   "source": [
    "Voyons comment fonctionne le code ci-dessus :\n",
    "\n",
    "- La première étape pour définir un réseau neuronal (qu’il s’agisse d’un CNN ou non) dans PyTorch est de définir une classe qui hérite `nn.Module` car elle contient de nombreuses méthodes que nous devrons utiliser.\n",
    "- Il y a deux étapes principales après cela. La première consiste à initialiser les couches que nous allons utiliser dans notre CNN à l’intérieur de `__init__`, et l’autre consiste à définir l’ordre dans lequel ces couches traiteront l’image. Ceci est défini à l’intérieur de la fonction `forward`.\n",
    "- Pour l’architecture elle-même, nous définissons d’abord les couches convolutives à l’aide de la fonction `nn.Conv2D` avec la taille de noyau appropriée et les canaux d’entrée/sortie. Nous appliquons également la fonction de mise en commun maximale `nn.MaxPool2D`. La bonne chose à propos de PyTorch est que nous pouvons combiner la couche convolutive, la fonction d’activation et le pool maximum en une seule couche (ils seront appliqués séparément, mais cela aide à l’organisation) en utilisant la fonction `nn.Sequential`\n",
    "- Ensuite, nous définissons les couches entièrement connectées en utilisant linear (`nn.Linear`) et dropout (`nn.Dropout`) ainsi que la fonction d’activation ReLu (`nn.ReLU`) et les combinons avec la fonction `nn.Sequential`.\n",
    "- Enfin, notre dernière couche produit 10 neurones qui sont nos prédictions finales pour les 10 classes d’objets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad603b-95fe-4d2f-ab65-cc2ae096e648",
   "metadata": {},
   "source": [
    "## **Définition des hyperparamètres**\n",
    "Avant l’entraînement, nous devons définir certains hyperparamètres, tels que la fonction de perte et l’optimiseur à utiliser, ainsi que la taille du lot, le taux d’apprentissage et le nombre d’époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f5969-6152-4891-b9fa-0965b5754bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.005\n",
    "\n",
    "model = AlexNet(num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b3dbc-2746-47a1-afaf-3507340952fb",
   "metadata": {},
   "source": [
    "Nous commençons par définir des hyperparamètres simples (époques, taille de lot et taux d’apprentissage) et initialiser notre modèle en utilisant le nombre de classes comme argument, qui dans ce cas est de 10 avec le transfert du modèle vers le périphérique approprié (CPU ou GPU). Ensuite, nous définissons notre fonction de coût comme perte d’entropie croisée et l’optimiseur comme Adam. Il y a beaucoup de choix pour ceux-ci, mais ceux-ci ont tendance à donner de bons résultats avec le modèle et les données données. Enfin, nous définissons `total_step` pour mieux suivre les étapes lors de l’entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd885d54-f42a-4503-a172-45d91af32f15",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "Nous sommes prêts à entraîner notre modèle à ce stade :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe963a-c99a-4044-9e64-929b78913905",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb41d0-a280-4a5a-9bba-622af5e1a03d",
   "metadata": {},
   "source": [
    "Voyons ce que fait le code :\n",
    "\n",
    "- Nous commençons par itérer sur le nombre d’époques, puis sur les lots dans nos données d’entraînement\n",
    "- Nous convertissons les images et les étiquettes en fonction de l’appareil que nous utilisons, c’est-à-dire GPU ou CPU\n",
    "- Dans le forward pass, nous faisons des prédictions à l’aide de notre modèle et calculons la perte en fonction de ces prédictions et de nos étiquettes réelles\n",
    "- Ensuite, nous effectuons la passe arrière où nous mettons à jour nos poids pour améliorer notre modèle\n",
    "- Nous mettons ensuite les dégradés à zéro avant chaque mise à jour à l’aide de la fonction `optimizer.zero_grad()`\n",
    "- Ensuite, nous calculons les nouveaux gradients à l’aide de la fonction `loss.backward()`\n",
    "- Et enfin, nous mettons à jour les poids avec la fonction `optimizer.step()`\n",
    "- De plus, à la fin de chaque époque, nous utilisons également notre jeu de validation pour calculer la précision du modèle. Dans ce cas, nous n’avons pas besoin de gradients, nous utilisons `with torch.no_grad()` donc pour une évaluation plus rapide\n",
    "\n",
    "\n",
    "Nous pouvons voir la sortie comme suit :\n",
    "\n",
    "<img src=\"images/TLVA.png\" alt=\"Perte d’entraînement et précision de la validation\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e705055-e7b3-4dd9-a8f4-3d27d6ff091a",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, la perte diminue à chaque époque, ce qui montre que notre modèle est effectivement en train d’apprendre. Notez que cette perte se trouve sur l’ensemble d’apprentissage, et si la perte est beaucoup trop faible, cela peut indiquer un surapprentissage. C’est pourquoi nous utilisons également le kit de validation. La précision semble augmenter sur l’ensemble de validation, ce qui indique qu’il y a peu de chances de surapprentissage. Testons maintenant notre modèle pour voir comment il fonctionne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66fe04-b499-4564-b595-fa6160f8fa7b",
   "metadata": {},
   "source": [
    "## Test\n",
    "Maintenant, voyons comment notre modèle se comporte sur des données invisibles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8df22-0212-4ef8-b9bb-a7dd14f28721",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f82bd-350c-42b0-bfa9-f1f2e36ee49e",
   "metadata": {},
   "source": [
    "Notez que le code est exactement le même que pour nos besoins de validation.\n",
    "\n",
    "En utilisant le modèle et en nous entraînant pour seulement 6 époques, nous semblons obtenir une précision d’environ 78,8 % sur l’ensemble de validation, ce qui semble suffisant.<br><br>\n",
    "<img src='images/testing-Accuracy.png' alt='Précision des tests' width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbf529-b28a-4b48-8146-60a5d71fb331",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<p style=\"background-color:#478CCF;font-family:Georgia;color:teal;font-size:105%;text-align:center;border-radius:10px 10px;border-style: solid;border-width:17px;border-color:#478CCF;\"></p>\n",
    "<h1 style=\"color:black;font-size:32px;font-family:Georgia;text-align:center;\"><strong>Conclusion <strong style=\"color:#ff0000;font-size:30px;font-family:Georgia;\"><strong style=\"color:black;font-size:32px;font-family:Georgia;\"></strong></strong></strong></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad983bc5-3352-40f2-819f-ddcdba251008",
   "metadata": {},
   "source": [
    "\n",
    "Concluons maintenant ce que nous avons fait :\n",
    "\n",
    "- Nous avons commencé par comprendre l’architecture et les différents types de couches du modèle AlexNet\n",
    "- Ensuite, nous avons chargé et prétraité le jeu de données CIFAR10 à l’aide de `torchvision`\n",
    "- Ensuite, nous avions l’habitude de construire notre modèle AlexNet à partir de zéro `PyTorch`\n",
    "- Enfin, nous avons entraîné et testé notre modèle sur le jeu de données CIFAR10, et le modèle semblait bien fonctionner sur le jeu de données de test avec un entraînement minimal (6 époques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22469ba-5b98-490f-8b8a-4cb091b87289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
